{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Data Processing Pipeline\n",
    "## Document Loading\n",
    "\n",
    "Implement PDF document loader\n",
    "Process website content from CSV\n",
    "Create unified document format\n",
    "\n",
    "\n",
    "## Text Processing\n",
    "\n",
    "Split documents into appropriate chunks\n",
    "Clean and normalize text\n",
    "Handle special characters and formatting\n",
    "\n",
    "\n",
    "## Initial Testing\n",
    "\n",
    "Verify all documents are properly loaded\n",
    "Check text quality and chunking results"
   ],
   "id": "db8b4f8b24975026"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d3819636220f03f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAG Implementation\n",
    "## Setup Vector Store (Chroma)\n",
    "\n",
    "Initialize Chroma database\n",
    "Configure embedding model\n",
    "Create indexing pipeline\n",
    "\n",
    "\n",
    "## LLM Integration\n",
    "\n",
    "Setup open source LLM (e.g., Llama 2 or Mistral)\n",
    "Configure model parameters\n",
    "Create prompting templates\n",
    "\n",
    "\n",
    "## RAG Pipeline\n",
    "\n",
    "Implement retrieval logic\n",
    "Create answer generation pipeline\n",
    "Add conversation memory"
   ],
   "id": "4774cff5e6e0ef2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install langchain langchain-ollama ollama",
   "id": "7a15821217090fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "model = OllamaLLM(model=\"llama3.2\")"
   ],
   "id": "f2a6881667d7e959"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "result = model.invoke(input=\"what was my previous question?\")\n",
    "result"
   ],
   "id": "7d95c5d0de3df070"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
